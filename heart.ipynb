{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heart.csv', 'heart.ipynb', 'requirements.txt']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "295   63    1   0       140   187    0        0      144      1      4.0   \n",
       "219   48    1   0       130   256    1        0      150      1      0.0   \n",
       "164   38    1   2       138   175    0        1      173      0      0.0   \n",
       "14    58    0   3       150   283    1        0      162      0      1.0   \n",
       "57    45    1   0       115   260    0        0      185      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "295      2   2     3       0  \n",
       "219      2   2     3       0  \n",
       "164      2   4     2       1  \n",
       "14       2   0     2       1  \n",
       "57       2   0     2       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age:\t\t\tage\n",
      "sex:\t\t\t1: male, 0: female\n",
      "cp:\t\t\tchest pain type, 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic\n",
      "trestbps:\t\t\tresting blood pressure\n",
      "chol:\t\t\t serum cholestoral in mg/dl\n",
      "fbs:\t\t\tfasting blood sugar > 120 mg/dl\n",
      "restecg:\t\t\tresting electrocardiographic results (values 0,1,2)\n",
      "thalach:\t\t\t maximum heart rate achieved\n",
      "exang:\t\t\texercise induced angina\n",
      "oldpeak:\t\t\toldpeak = ST depression induced by exercise relative to rest\n",
      "slope:\t\t\tthe slope of the peak exercise ST segment\n",
      "ca:\t\t\tnumber of major vessels (0-3) colored by flourosopy\n",
      "thal:\t\t\tthal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n"
     ]
    }
   ],
   "source": [
    "info = [\"age\",\"1: male, 0: female\",\"chest pain type, 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic\",\"resting blood pressure\",\" serum cholestoral in mg/dl\",\"fasting blood sugar > 120 mg/dl\",\"resting electrocardiographic results (values 0,1,2)\",\" maximum heart rate achieved\",\"exercise induced angina\",\"oldpeak = ST depression induced by exercise relative to rest\",\"the slope of the peak exercise ST segment\",\"number of major vessels (0-3) colored by flourosopy\",\"thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\"]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(info)):\n",
    "    print(dataset.columns[i]+\":\\t\\t\\t\"+info[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    303.000000\n",
       "mean       0.544554\n",
       "std        0.498835\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"target\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target      1.000000\n",
      "exang       0.436757\n",
      "cp          0.433798\n",
      "oldpeak     0.430696\n",
      "thalach     0.421741\n",
      "ca          0.391724\n",
      "slope       0.345877\n",
      "thal        0.344029\n",
      "sex         0.280937\n",
      "age         0.225439\n",
      "trestbps    0.144931\n",
      "restecg     0.137230\n",
      "chol        0.085239\n",
      "fbs         0.028046\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.corr()[\"target\"].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1    165\n",
      "0    138\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = dataset[\"target\"]\n",
    "\n",
    "sns.countplot(y)\n",
    "\n",
    "\n",
    "target_temp = dataset.target.value_counts()\n",
    "\n",
    "print(target_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of patience without heart problems: 45.54\n",
      "Percentage of patience with heart problems: 54.46\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of patience without heart problems: \"+str(round(target_temp[0]*100/303,2)))\n",
    "print(\"Percentage of patience with heart problems: \"+str(round(target_temp[1]*100/303,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predictors = dataset.drop(\"target\",axis=1)\n",
    "target = dataset[\"target\"]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Logistic Regression is: 85.25 %\n"
     ]
    }
   ],
   "source": [
    "score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Logistic Regression is: \"+str(score_lr)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Naive Bayes is: 85.25 %\n"
     ]
    }
   ],
   "source": [
    "score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Naive Bayes is: \"+str(score_nb)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "\n",
    "sv.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_svm = sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Linear SVM is: 81.97 %\n"
     ]
    }
   ],
   "source": [
    "score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Linear SVM is: \"+str(score_svm)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train,Y_train)\n",
    "Y_pred_knn=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using KNN is: 67.21 %\n"
     ]
    }
   ],
   "source": [
    "score_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_accuracy = 0\n",
    "\n",
    "\n",
    "for x in range(200):\n",
    "    dt = DecisionTreeClassifier(random_state=x)\n",
    "    dt.fit(X_train,Y_train)\n",
    "    Y_pred_dt = dt.predict(X_test)\n",
    "    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "        \n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=best_x)\n",
    "dt.fit(X_train,Y_train)\n",
    "Y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred_dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Decision Tree is: 81.97 %\n"
     ]
    }
   ],
   "source": [
    "score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "max_accuracy = 0\n",
    "\n",
    "\n",
    "for x in range(2000):\n",
    "    rf = RandomForestClassifier(random_state=x)\n",
    "    rf.fit(X_train,Y_train)\n",
    "    Y_pred_rf = rf.predict(X_test)\n",
    "    current_accuracy = round(accuracy_score(Y_pred_rf,Y_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "        \n",
    "\n",
    "rf = RandomForestClassifier(random_state=best_x)\n",
    "rf.fit(X_train,Y_train)\n",
    "Y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Decision Tree is: 90.16 %\n"
     ]
    }
   ],
   "source": [
    "score_rf = round(accuracy_score(Y_pred_rf,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_rf)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using XGBoost is: 83.61 %\n"
     ]
    }
   ],
   "source": [
    "score_xgb = round(accuracy_score(Y_pred_xgb,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using XGBoost is: \"+str(score_xgb)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu',input_dim=13))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:From d:\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8/8 [==============================] - 2s 5ms/step - loss: 25.9631 - accuracy: 0.4587\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.9703 - accuracy: 0.4587\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3686 - accuracy: 0.4545\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.9992 - accuracy: 0.5992\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6955 - accuracy: 0.5909\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.1427 - accuracy: 0.6240\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.4617 - accuracy: 0.6240\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.6908 - accuracy: 0.5785\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3646 - accuracy: 0.6116\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3825 - accuracy: 0.6033\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3028 - accuracy: 0.5950\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2680 - accuracy: 0.6116\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2497 - accuracy: 0.6074\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2370 - accuracy: 0.6116\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2202 - accuracy: 0.6157\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2123 - accuracy: 0.5992\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2109 - accuracy: 0.6074\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1725 - accuracy: 0.6116\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1631 - accuracy: 0.6157\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1494 - accuracy: 0.6198\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1340 - accuracy: 0.6198\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.1304 - accuracy: 0.5992\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.1110 - accuracy: 0.6240\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0911 - accuracy: 0.6281\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0860 - accuracy: 0.6116\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0768 - accuracy: 0.6281\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0514 - accuracy: 0.6281\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0575 - accuracy: 0.6281\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0290 - accuracy: 0.6322\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0208 - accuracy: 0.6364\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0505 - accuracy: 0.6033\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0110 - accuracy: 0.6488\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9823 - accuracy: 0.6446\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9694 - accuracy: 0.6405\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9568 - accuracy: 0.6529\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9514 - accuracy: 0.6364\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9516 - accuracy: 0.6488\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9314 - accuracy: 0.6446\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9234 - accuracy: 0.6488\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9020 - accuracy: 0.6446\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8884 - accuracy: 0.6405\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8848 - accuracy: 0.6612\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8903 - accuracy: 0.6446\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8492 - accuracy: 0.6612\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8440 - accuracy: 0.6694\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8436 - accuracy: 0.6694\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.6653\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8751 - accuracy: 0.6529\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8482 - accuracy: 0.6405\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7950 - accuracy: 0.6777\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7811 - accuracy: 0.6818\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7947 - accuracy: 0.6694\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8087 - accuracy: 0.6942\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.6860\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.6612\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.6736\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7426 - accuracy: 0.6777\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7202 - accuracy: 0.6860\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7266 - accuracy: 0.6942\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7163 - accuracy: 0.6860\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7010 - accuracy: 0.6777\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.6860\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7119 - accuracy: 0.6942\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.6942\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.6983\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.6983\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7025\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.7190\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.7273\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6901\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.7107\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.6777\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.7314\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7231\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.7397\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7273\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.7314\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7438\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6818\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7273\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7231\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7645\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7438\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7521\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7479\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7273\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7397\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7645\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.7438\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7355\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7603\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7562\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7686\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7355\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7727\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7397\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7769\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7727\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7851\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7810\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7769\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7645\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7851\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7686\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7810\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7727\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7769\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8099\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7893\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7934\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8017\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.8058\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8058\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7686\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7975\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8058\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8140\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8017\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7975\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7975\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8058\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8058\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8017\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8140\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8058\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8182\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8140\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8058\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8099\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8140\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8182\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8058\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8017\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7975\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8017\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8223\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8058\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8223\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8140\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8223\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8182\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8099\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8306\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8306\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8223\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8306\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8264\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8017\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8017\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8017\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8264\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8471\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8223\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8099\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8058\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8099\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8017\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8264\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8306\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8347\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8264\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8347\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8099\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8306\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8347\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8306\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8140\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8306\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8430\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8099\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8223\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8017\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8140\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8017\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8099\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8140\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8388\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8471\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8430\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8471\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8140\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8347\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8306\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8306\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8017\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8140\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8347\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8223\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8347\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8347\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8471\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8388\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8099\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8099\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8223\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8058\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7975\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8223\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7810\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8017\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8182\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8388\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8182\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8347\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8347\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8430\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8306\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8306\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8512\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8264\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8388\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8347\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8388\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8182\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8471\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8347\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8512\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8430\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8347\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8140\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8182\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7851\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8182\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8430\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8388\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8430\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8471\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8264\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8140\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8347\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8347\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8347\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8182\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8347\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8182\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8264\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8347\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8347\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8347\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8388\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8471\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8347\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8223\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8223\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8554\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8264\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8140\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8388\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8554\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8512\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8430\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8388\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8471\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.8264\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8430\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8347\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8306\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8388\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8306\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.7975\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8471\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8058\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8058\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8347\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8347\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8306\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8306\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8347\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8512\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8388\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8347\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8554\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8430\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8512\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8182\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8554\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8430\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8430\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8554\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3698 - accuracy: 0.8388\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8512\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8512\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8430\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8347\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8306\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8430\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8430\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8347\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.7934\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8264\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8347\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8017\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8264\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8099\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8099\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8223\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8099\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8306\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8388\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25646ca3350>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_nn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = [round(x[0]) for x in Y_pred_nn]\n",
    "\n",
    "Y_pred_nn = rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Neural Network is: 78.69 %\n"
     ]
    }
   ],
   "source": [
    "score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Logistic Regression is: 85.25 %\n",
      "The accuracy score achieved using Naive Bayes is: 85.25 %\n",
      "The accuracy score achieved using Support Vector Machine is: 81.97 %\n",
      "The accuracy score achieved using K-Nearest Neighbors is: 67.21 %\n",
      "The accuracy score achieved using Decision Tree is: 81.97 %\n",
      "The accuracy score achieved using Random Forest is: 90.16 %\n",
      "The accuracy score achieved using XGBoost is: 83.61 %\n",
      "The accuracy score achieved using Neural Network is: 78.69 %\n"
     ]
    }
   ],
   "source": [
    "scores = [score_lr,score_nb,score_svm,score_knn,score_dt,score_rf,score_xgb,score_nn]\n",
    "algorithms = [\"Logistic Regression\",\"Naive Bayes\",\"Support Vector Machine\",\"K-Nearest Neighbors\",\"Decision Tree\",\"Random Forest\",\"XGBoost\",\"Neural Network\"]    \n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
